# å¼ºåŒ–å­¦ä¹ ç®—æ³•å¤ç°è·¯çº¿å›¾

æœ¬æ–‡æ¡£åˆ—å‡ºäº†ä»åŸºç¡€åˆ°å‰æ²¿çš„å¼ºåŒ–å­¦ä¹ ç®—æ³•æ¸…å•ï¼ŒæŒ‰ç…§éš¾åº¦å’Œä¾èµ–å…³ç³»ç»„ç»‡ã€‚

## ğŸ“š ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€ç®—æ³• (Tabular Methods)

### 1. åŠ¨æ€è§„åˆ’ (Dynamic Programming)
- [ ] **Policy Iteration** - ç­–ç•¥è¿­ä»£
- [ ] **Value Iteration** - ä»·å€¼è¿­ä»£
- [ ] **Environment**: GridWorld (è‡ªå®šä¹‰ç®€å•ç¯å¢ƒ)

### 2. è’™ç‰¹å¡æ´›æ–¹æ³• (Monte Carlo Methods)
- [ ] **MC Prediction** - MCé¢„æµ‹
- [ ] **MC Control with Îµ-greedy** - MCæ§åˆ¶
- [ ] **Off-policy MC** - ç¦»ç­–ç•¥MC
- [ ] **Environment**: Blackjack, GridWorld

### 3. æ—¶åºå·®åˆ†å­¦ä¹  (Temporal Difference Learning)
- [ ] **TD(0)** - å•æ­¥TD
- [ ] **SARSA** - åœ¨çº¿ç­–ç•¥TDæ§åˆ¶
- [ ] **Q-Learning** - ç¦»çº¿ç­–ç•¥TDæ§åˆ¶
- [ ] **Expected SARSA** - æœŸæœ›SARSA
- [ ] **n-step TD** - næ­¥TD
- [ ] **TD(Î»)** - TD(lambda)
- [ ] **Environment**: CliffWalking, FrozenLake, Taxi

## ğŸ¯ ç¬¬äºŒé˜¶æ®µï¼šä»·å€¼å‡½æ•°é€¼è¿‘ (Value Function Approximation)

### 4. æ·±åº¦Qç½‘ç»œç³»åˆ— (DQN Family)
- [ ] **DQN** - Deep Q-Network (2015)
- [ ] **Double DQN** - åŒé‡DQN (2016)
- [ ] **Dueling DQN** - å¯¹å†³DQN (2016)
- [ ] **Prioritized Experience Replay (PER)** - ä¼˜å…ˆç»éªŒå›æ”¾ (2016)
- [ ] **Noisy DQN** - å™ªå£°ç½‘ç»œ (2017)
- [ ] **Categorical DQN (C51)** - åˆ†ç±»DQN (2017)
- [ ] **Rainbow** - é›†å¤§æˆè€… (2018)
- [ ] **Environment**: CartPole, LunarLander, Atari (Pong, Breakout)

## ğŸš€ ç¬¬ä¸‰é˜¶æ®µï¼šç­–ç•¥æ¢¯åº¦æ–¹æ³• (Policy Gradient Methods)

### 5. åŸºç¡€ç­–ç•¥æ¢¯åº¦
- [ ] **REINFORCE** - è’™ç‰¹å¡æ´›ç­–ç•¥æ¢¯åº¦ (1992)
- [ ] **REINFORCE with Baseline** - å¸¦åŸºçº¿çš„REINFORCE
- [ ] **Actor-Critic** - æ¼”å‘˜-è¯„è®ºå®¶
- [ ] **Environment**: CartPole, LunarLander

### 6. é«˜çº§Actor-Critic
- [ ] **A2C** - Advantage Actor-Critic (2016)
- [ ] **A3C** - Asynchronous A2C (2016)
- [ ] **GAE** - Generalized Advantage Estimation (2016)
- [ ] **Environment**: Atariæ¸¸æˆ

## ğŸª ç¬¬å››é˜¶æ®µï¼šç°ä»£æ·±åº¦RL (Modern Deep RL)

### 7. ä¿¡èµ–åŸŸå’Œè‡ªç„¶æ¢¯åº¦æ–¹æ³•
- [ ] **TRPO** - Trust Region Policy Optimization (2015)
- [ ] **PPO** - Proximal Policy Optimization (2017) â­ æœ€æµè¡Œ
- [ ] **Environment**: MuJoCo (HalfCheetah, Walker2d, Humanoid)

### 8. ç¦»çº¿ç­–ç•¥Actor-Critic
- [ ] **DDPG** - Deep Deterministic Policy Gradient (2016)
- [ ] **TD3** - Twin Delayed DDPG (2018)
- [ ] **SAC** - Soft Actor-Critic (2018) â­ é«˜æ•ˆç¨³å®š
- [ ] **Environment**: MuJoCoè¿ç»­æ§åˆ¶ä»»åŠ¡

## ğŸŒŸ ç¬¬äº”é˜¶æ®µï¼šå‰æ²¿ç®—æ³• (Cutting-edge)

### 9. æ¨¡å‹åŸºç¡€RL (Model-Based RL)
- [ ] **Dyna-Q** - æ•´åˆè§„åˆ’å’Œå­¦ä¹ 
- [ ] **MBPO** - Model-Based Policy Optimization (2019)
- [ ] **Dreamer** - ä¸–ç•Œæ¨¡å‹ (2020)
- [ ] **MuZero** - æ— éœ€äº†è§£è§„åˆ™çš„å›´æ£‹AI (2020)

### 10. å¤šæ™ºèƒ½ä½“RL (Multi-Agent RL)
- [ ] **IQL** - Independent Q-Learning
- [ ] **QMIX** - Qå€¼æ··åˆç½‘ç»œ (2018)
- [ ] **MADDPG** - Multi-Agent DDPG (2017)
- [ ] **MAPPO** - Multi-Agent PPO (2021)

### 11. ç¦»çº¿RL (Offline RL)
- [ ] **BCQ** - Batch-Constrained Q-learning (2019)
- [ ] **CQL** - Conservative Q-Learning (2020)
- [ ] **IQL** - Implicit Q-Learning (2021)
- [ ] **Decision Transformer** - åºåˆ—å»ºæ¨¡æ–¹æ³• (2021)

### 12. åˆ†å±‚RL (Hierarchical RL)
- [ ] **Options Framework** - é€‰é¡¹æ¡†æ¶
- [ ] **HAC** - Hierarchical Actor-Critic (2018)
- [ ] **HIRO** - Data-Efficient HRL (2018)

### 13. å…ƒå­¦ä¹ å’Œè¿ç§»å­¦ä¹ 
- [ ] **MAML** - Model-Agnostic Meta-Learning (2017)
- [ ] **RLÂ²** - Fast RL via Slow RL (2016)

### 14. åŸºäºTransformerçš„æ–¹æ³•
- [ ] **Decision Transformer** (2021) â­ çƒ­é—¨
- [ ] **Trajectory Transformer** (2021)
- [ ] **Gato** - å¤šä»»åŠ¡é€šç”¨Agent (2022)

## ğŸ¯ æ¨èå­¦ä¹ è·¯å¾„

### åˆå­¦è€…è·¯å¾„ï¼ˆ2-3ä¸ªæœˆï¼‰
1. GridWorld + Policy/Value Iteration
2. Q-Learning + SARSA (FrozenLake, Taxi)
3. DQN (CartPole, LunarLander)
4. REINFORCE + A2C (CartPole)
5. PPO (ç®€å•MuJoCoä»»åŠ¡)

### è¿›é˜¶è·¯å¾„ï¼ˆ3-6ä¸ªæœˆï¼‰
1. å®Œæˆåˆå­¦è€…è·¯å¾„
2. Rainbow DQN (Atariæ¸¸æˆ)
3. PPO + GAE (å¤æ‚ç¯å¢ƒ)
4. SAC (è¿ç»­æ§åˆ¶)
5. é€‰æ‹©ä¸€ä¸ªå‰æ²¿æ–¹å‘æ·±å…¥

### ç ”ç©¶è·¯å¾„ï¼ˆ6+ä¸ªæœˆï¼‰
1. å®ŒæˆåŸºç¡€+è¿›é˜¶
2. å®ç°SOTAç®—æ³•
3. é˜…è¯»æœ€æ–°è®ºæ–‡
4. å°è¯•æ”¹è¿›å’Œåˆ›æ–°

## ğŸ“Š ç¯å¢ƒéš¾åº¦è¯„ä¼°

- **å…¥é—¨**: GridWorld, FrozenLake, CartPole
- **ç®€å•**: Taxi, CliffWalking, MountainCar
- **ä¸­ç­‰**: LunarLander, Atari (Pong)
- **å›°éš¾**: Atari (Breakout), MuJoCo (HalfCheetah)
- **ä¸“å®¶**: MuJoCo (Humanoid), å¤šæ™ºèƒ½ä½“ç¯å¢ƒ

## ğŸ”— å‚è€ƒèµ„æº

- **æ•™æ**: Sutton & Barto - Reinforcement Learning: An Introduction
- **è¯¾ç¨‹**: DeepMind x UCL RL Course, Stanford CS234
- **è®ºæ–‡**: [Spinning Up in Deep RL (OpenAI)](https://spinningup.openai.com/)
- **ä»£ç **: CleanRL, Stable-Baselines3

